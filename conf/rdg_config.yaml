data:
  general:
    input_size: 299
    n_fft: 512
    n_mels: 40
    win_length: 250
    hop_length: 100
    n_class: 103 # get from dataset externally 
    batch_size: 70
    num_workers: 32
  train:
    json_file: ../data/train_flower_en2vi.json
    img_path: ../data/image_oxford/image_oxford
    audio_path: ../data/oxford_audio/oxford_audio
    input_size: ${data.general.input_size}
    n_fft: ${data.general.n_fft}
    n_mels: ${data.general.n_mels}
    win_length: ${data.general.win_length}
    hop_length: ${data.general.hop_length}
  test:
    json_file: ../data/test_flower_en2vi.json
    img_path: ../data/image_oxford/image_oxford
    audio_path: ../data/oxford_audio/oxford_audio
    input_size: ${data.general.input_size}
    n_fft: ${data.general.n_fft}
    n_mels: ${data.general.n_mels}
    win_length: ${data.general.win_length}
    hop_length: ${data.general.hop_length}
    
model:
  generator:
    latent_space_dim: 100
    speech_emb_dim: 1024
    gan_emb_dim: 128
    gen_dim: 64
  discriminator:
    disc_dim: 64
    gan_emb_dim: ${model.generator.gan_emb_dim}
  relation_classifier:
    inp_dim: 2048
    hid_dim: 128
  image_encoder:
    output_dim: 1024
  speech_encoder:
    input_dim: ${data.general.n_mels}
    cnn_dim: [64, 128]
    kernel_size: 6
    stride: 2
    rnn_dim: 512
    rnn_num_layers: 2
    rnn_type: gru
    rnn_dropout: 0.1
    rnn_bidirectional: True
    attn_heads: 1
    attn_dropout: 0.1
  

optimizer:
  lr: 0.0002

scheduler:
  use: true
  pct_start: 0.5

experiment:
  train: true
  test: true
  max_epoch: 100
  log_wandb: true
  specific_params:
    latent_space_dim: ${model.generator.latent_space_dim}
    img_dims:
      - 64
      - 128
      - 256
    kl_loss_coef: 2

loss:
  beta: 10

ckpt:
  speech_encoder: ckpt/speech_encoder.pt
  image_encoder: ckpt/image_encoder.pt